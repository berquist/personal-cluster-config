SlurmctldHost=osmium
#
GresTypes=gpu
MpiDefault=none
ProctrackType=proctrack/cgroup
ReturnToService=1
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurm/slurmd
SlurmUser=slurm
StateSaveLocation=/var/spool/slurm/slurmctld
SwitchType=switch/none
TaskPlugin=task/affinity,task/cgroup
TaskPluginParam=Sched
Prolog=/etc/slurm-llnl/prolog
TaskProlog=/etc/slurm-llnl/task_prolog
#
#
# SCHEDULING
SchedulerType=sched/backfill
SelectType=select/cons_tres
# Use CR_Core_Memory to keep track of memory
SelectTypeParameters=CR_Core
#
#
# PREEMPTION
PreemptExemptTime=0:10:00
PreemptMode=REQUEUE
PreemptType=preempt/partition_prio
JobRequeue=1
#
#
# LOGGING AND ACCOUNTING
SlurmdDebug=debug5
SlurmctldDebug=debug5
AccountingStorageEnforce=associations,limits,qos
AccountingStorageTRES=gres/gpu
AccountingStorageType=accounting_storage/slurmdbd
AccountingStoreJobComment=YES
ClusterName=osmium-cluster
JobAcctGatherType=jobacct_gather/cgroup
JobCompLoc=/var/log/slurm-llnl/job_completions
JobCompType=jobcomp/filetxt
#
#
# COMPUTE NODES
# NodeName=osmium CPUs=1 RealMemory=32000 Sockets=1 CoresPerSocket=16 ThreadsPerCore=1 State=UNKNOWN
# I don't understand why `lstopo -> slurmd -C` reports this...
NodeName=osmium CPUs=32 Boards=1 SocketsPerBoard=2 CoresPerSocket=8 ThreadsPerCore=2 RealMemory=32034 State=UNKNOWN Gres=gpu:rtx2070:1
#
#
# PARTITIONS
PartitionName=DEFAULT OverSubscribe=NO
PartitionName=scavenge  Nodes=osmium Default=Yes MaxTime=12:00:00 State=UP PriorityTier=1
PartitionName=ephemeral Nodes=osmium             MaxTime=12:00:00 State=UP PriorityTier=1 PreemptMode=CANCEL
PartitionName=apples    Nodes=osmium             MaxTime=INFINITE State=UP PriorityTier=2
PartitionName=oranges   Nodes=osmium             MaxTime=INFINITE State=UP PriorityTier=3
